{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize in RGB the mixed atoms\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def make_plot(elements, tot_num_atoms, num_effective_atoms, iteration, dict_list):\n",
    "    # delete O_pos_one.txt and weights_one.txt if they exist\n",
    "    file_path = 'O_pos_one.txt'\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    else:\n",
    "        print(f\"File '{file_path}' does not exist, so it cannot be deleted.\")\n",
    "    file_path = 'weights_one.txt'\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    else:\n",
    "        print(f\"File '{file_path}' does not exist, so it cannot be deleted.\")\n",
    "    \n",
    "    # create O_pos_one.txt\n",
    "    with open('OH_pos.txt', 'r') as file:\n",
    "        all_lines = file.readlines()\n",
    "        # Iterate over each line in the document\n",
    "        for line_number, line in enumerate(all_lines):\n",
    "            # Check if the line contains exactly \"Iteration 1\"\n",
    "            if line.strip() == f\"Iteration {iteration}\":\n",
    "                relevant_lines = all_lines[line_number:line_number + 6 + tot_num_atoms]\n",
    "                break\n",
    "        else:\n",
    "            print(f\"The line 'Iteration {iteration}' was not found in O_pos.txt.\")\n",
    "    with open('O_pos_one.txt', 'w') as file:\n",
    "        file.write(''.join(relevant_lines))\n",
    "\n",
    "    # create weights_one.txt\n",
    "    with open('min_progress.txt', 'r') as file:\n",
    "        all_lines = file.readlines()\n",
    "        # Iterate over each line in the document\n",
    "        for line_number, line in enumerate(all_lines):\n",
    "            # Check if the line contains exactly \"Iteration 1\"\n",
    "            if f\"Iteration {iteration}\" in line.strip():\n",
    "                relevant_lines = all_lines[line_number:line_number + num_effective_atoms + 2]\n",
    "                break\n",
    "        else:\n",
    "            print(f\"The line 'Iteration {iteration}' was not found in min_progress.txt.\")\n",
    "    with open('weights_one.txt', 'w') as file:\n",
    "        file.write(''.join(relevant_lines))\n",
    "    \n",
    "    # extract positions and lattice\n",
    "    with open('O_pos_one.txt', 'r') as file:\n",
    "        reading_lattice = False\n",
    "        reading_positions = False\n",
    "        lattice = []\n",
    "        mixpositions = []\n",
    "        otherpositions = []\n",
    "        atomtype = []\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading and trailing whitespace\n",
    "            if 'Lattice' in line:\n",
    "                reading_lattice = True\n",
    "                continue  # Skip the current iteration and move to the next line\n",
    "            elif 'Positions' in line:\n",
    "                reading_lattice = False\n",
    "                reading_positions = True\n",
    "                continue\n",
    "            elif reading_lattice:\n",
    "                lattice.append(line)\n",
    "                if len(lattice) == 3:  # Assuming there are always 3 lines for lattice\n",
    "                    reading_lattice = False\n",
    "            elif reading_positions:\n",
    "                if len(mixpositions) + len(otherpositions) < tot_num_atoms:\n",
    "                    positions_split = line.split()\n",
    "                    if 'mix' in line:\n",
    "                        mixpositions.append(f'{positions_split[2]} {positions_split[3]} {positions_split[4]}')\n",
    "                    else:\n",
    "                        atomtype.append(positions_split[1])\n",
    "                        otherpositions.append(f'{positions_split[2]} {positions_split[3]} {positions_split[4]}')\n",
    "                else:\n",
    "                    break  # Stop reading file if we have read all required positions\n",
    "\n",
    "    # convert lattice and positions into vectors\n",
    "    L = np.zeros((3, 3))\n",
    "    for i in range(3):\n",
    "        lattice_split = lattice[i].split()\n",
    "        # note that columns of lattV are the Bravais lattice vectors\n",
    "        L[i, :] = np.array([float(lattice_split[0]), float(lattice_split[1]), float(lattice_split[2])])\n",
    "    mixposV = np.zeros((len(mixpositions), 3))\n",
    "\n",
    "    for i in range(len(mixpositions)):\n",
    "        pos_split = mixpositions[i].split()\n",
    "        mixposV[i, :] = np.array([float(pos_split[0]), float(pos_split[1]), float(pos_split[2])])\n",
    "    mixP = mixposV.T # make columns the fractional vectors\n",
    "\n",
    "    otherposV = np.zeros((len(otherpositions), 3))\n",
    "    for i in range(len(otherpositions)):\n",
    "        pos_split = otherpositions[i].split()\n",
    "        otherposV[i, :] = np.array([float(pos_split[0]), float(pos_split[1]), float(pos_split[2])])\n",
    "    otherP = otherposV.T # make columns the fractional vectors\n",
    "\n",
    "    # get weights of each mixed atom\n",
    "    with open('weights_one.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        # Initialize a list to hold the extracted numbers\n",
    "        weights = []\n",
    "        # Iterate over each line\n",
    "        for line in lines:\n",
    "            split_line = line.strip().split()\n",
    "            # Check if the line contains information on weights by looking for any of the elements\n",
    "            if any(elem in split_line for elem in elements):\n",
    "                parts = split_line\n",
    "                line_weights = []\n",
    "                for elem in elements:\n",
    "                    if elem in parts:  # Check if the element is in the line to avoid errors\n",
    "                        # Extract the weight for each element and append to the line_weights list\n",
    "                        weight = float(parts[parts.index(elem) - 1])\n",
    "                        line_weights.append(weight)\n",
    "                weights.append(line_weights)\n",
    "        # extract binding energies\n",
    "        for line in lines:\n",
    "            if 'binding' in line:\n",
    "                split_line = line.strip().split()\n",
    "                HEA_binding = format(float(split_line[4]), '.2f')\n",
    "                break\n",
    "        # Convert the list of lists into a NumPy array\n",
    "        W = np.array(weights)\n",
    "    # get cartesian positions of atoms (columns are the positions)\n",
    "    mixC = L @ mixP\n",
    "    otherC = L @ otherP\n",
    "\n",
    "    atom_dict_list = []\n",
    "    k = 1\n",
    "    for i in range(len(mixpositions)):\n",
    "        composition = {}\n",
    "        for el in elements:\n",
    "            composition[el] = float(W[i, elements.index(el)])\n",
    "        composition['O'] = 0.0\n",
    "        composition['H'] = 0.0\n",
    "        atom_dict_list.append({\n",
    "                            \"id\": k,\n",
    "                            \"position\": mixC[:, i],\n",
    "                            \"composition\": composition\n",
    "                            })\n",
    "        k+=1\n",
    "\n",
    "    for i in range(len(otherpositions)):\n",
    "        if atomtype[i] == 'O':\n",
    "            composition = {}\n",
    "            for el in elements:\n",
    "                composition[el] = 0.0\n",
    "            composition['O'] = 1.0\n",
    "            composition['H'] = 0.0\n",
    "            atom_dict_list.append({\n",
    "                                \"id\": k,\n",
    "                                \"position\": otherC[:, i],\n",
    "                                \"composition\": composition\n",
    "                                })\n",
    "        elif atomtype[i] == 'H':\n",
    "            composition = {}\n",
    "            for el in elements:\n",
    "                composition[el] = 0.0\n",
    "            composition['O'] = 0.0\n",
    "            composition['H'] = 1.0\n",
    "            atom_dict_list.append({\n",
    "                                \"id\": k,\n",
    "                                \"position\": otherC[:, i],\n",
    "                                \"composition\": composition\n",
    "                                })\n",
    "            \n",
    "        k+=1\n",
    "    \n",
    "    dict_list.append({\n",
    "                        \"frame\": iteration,\n",
    "                        \"binding\": float(HEA_binding),\n",
    "                        \"atoms\": atom_dict_list\n",
    "                    })\n",
    "    \n",
    "    return dict_list, L\n",
    "\n",
    "\n",
    "\n",
    "#############################################################\n",
    "elements = ['Co', 'Cr', 'Ni', 'V']\n",
    "numinterp = 1\n",
    "\n",
    "for run_iter in range(1, 19):\n",
    "    try:\n",
    "        os.chdir(f'/Users/justint/Library/CloudStorage/OneDrive-Personal/Desktop/Academic Stuff/Arias Research/EAT/Paper_EAT_2025/Blender/EAT_noMag/run{run_iter}+1_6')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    with open('min_progress.txt', 'r') as file:\n",
    "        file_lines = file.readlines()\n",
    "    for line in file_lines:\n",
    "        if 'Iteration' in line:\n",
    "            num_iterations = int(line.strip().split()[1][:-1])\n",
    "\n",
    "    with open('OH_pos.txt', 'r') as file:\n",
    "        file_lines = file.readlines()\n",
    "    tot_num_atoms = 0\n",
    "    num_effective_atoms = 0\n",
    "    for line in file_lines:\n",
    "        if line.strip():\n",
    "            if line.strip().split()[0] == 'ion':\n",
    "                tot_num_atoms += 1\n",
    "            if 'mix' in line:\n",
    "                num_effective_atoms += 1\n",
    "            if 'Iteration 2' in line:\n",
    "                break\n",
    "    \n",
    "    dict_list = []\n",
    "    for i in range(1, num_iterations+1):\n",
    "        dict_list, lattice_vectors = make_plot(elements, tot_num_atoms, num_effective_atoms, i, dict_list)\n",
    "\n",
    "    elements_full = elements + ['O', 'H']\n",
    "\n",
    "    # interpolate between frames\n",
    "    x = np.linspace(0, 1, numinterp+1)\n",
    "    interp_list = []\n",
    "    for j in range(num_iterations-1):\n",
    "        for i in range(numinterp):\n",
    "            atom_list = []\n",
    "            for k in range(tot_num_atoms):\n",
    "                new_atom_dict = {}\n",
    "                new_atom_dict[\"id\"] = k+1\n",
    "                atoms_dict_comp = {}\n",
    "                for element in elements_full:\n",
    "                    atoms_dict_comp[element] = x[i] * (dict_list[j+1]['atoms'][k]['composition'][element] - dict_list[j]['atoms'][k]['composition'][element]) + dict_list[j]['atoms'][k]['composition'][element]\n",
    "                new_atom_dict['composition'] = atoms_dict_comp\n",
    "                position_temp = x[i] * (dict_list[j+1]['atoms'][k]['position'] - dict_list[j]['atoms'][k]['position']) + dict_list[j]['atoms'][k]['position']\n",
    "                new_atom_dict[\"position\"] = position_temp.tolist()\n",
    "                atom_list.append(new_atom_dict)\n",
    "\n",
    "            interp_list.append({\n",
    "                                \"frame\": j * numinterp + i,\n",
    "                                \"binding\": x[i] * (dict_list[j+1]['binding'] - dict_list[j]['binding']) + dict_list[j]['binding'],\n",
    "                                \"atoms\": atom_list\n",
    "            })\n",
    "\n",
    "    # Final frame\n",
    "    atom_list = []\n",
    "    for k in range(tot_num_atoms):\n",
    "        new_atom_dict = {}\n",
    "        new_atom_dict[\"id\"] = k+1\n",
    "        atoms_dict_comp = {}\n",
    "        for element in elements_full:\n",
    "            atoms_dict_comp[element] = dict_list[-1]['atoms'][k]['composition'][element]\n",
    "        new_atom_dict['composition'] = atoms_dict_comp\n",
    "        position_temp = dict_list[-1]['atoms'][k]['position']\n",
    "        new_atom_dict[\"position\"] = position_temp.tolist()\n",
    "        atom_list.append(new_atom_dict)\n",
    "    interp_list.append({\n",
    "                        \"frame\": num_iterations * numinterp + numinterp-1,\n",
    "                        \"binding\": dict_list[-1]['binding'],\n",
    "                        \"atoms\": atom_list\n",
    "            })  # Append the last frame\n",
    "    \n",
    "    # # extend unit cell in x-y direction\n",
    "    # interp_list_extended = []\n",
    "    # for entry in interp_list:\n",
    "    #     atom_list = []\n",
    "    #     for k in range(tot_num_atoms):\n",
    "    #         for i in range(2):\n",
    "    #             for j in range(2):\n",
    "    #                 new_atom_dict = {}\n",
    "    #                 new_atom_dict[\"id\"] = k*(2*2) + (i+1)*2 + (j+1) - 2\n",
    "    #                 new_atom_dict['composition'] = entry[\"atoms\"][k][\"composition\"]\n",
    "    #                 position_temp = np.array(entry['atoms'][k]['position']) + i * lattice_vectors[0, :] + j * lattice_vectors[1, :]\n",
    "    #                 new_atom_dict[\"position\"] = position_temp.tolist()\n",
    "    #                 atom_list.append(new_atom_dict)\n",
    "    #     interp_list_extended.append({\n",
    "    #                             \"frame\": entry['frame'],\n",
    "    #                             \"binding\": entry['binding'],\n",
    "    #                             \"atoms\": atom_list\n",
    "    #         })\n",
    "\n",
    "\n",
    "\n",
    "    element_colors = {\n",
    "        'Co': (0.0, 1.0, 1.0),  # Cyan\n",
    "        'Cr': (0.0, 1.0, 0.0),  # Green\n",
    "        'Ni': (0.0, 0.0, 1.0),  # Blue\n",
    "        'V': (1.0, 1.0, 0.0),  # Yellow\n",
    "        'O': (1.0, 0.0, 0.0), # Red\n",
    "        'H': (1.0, 1.0, 1.0) # White\n",
    "    }\n",
    "\n",
    "    element_sizes = {\n",
    "        'Co': 2.2,\n",
    "        'Cr': 2.2,\n",
    "        'Ni': 2.2,\n",
    "        'V': 2.2,\n",
    "        'O': 1.0,\n",
    "        'H': 0.6\n",
    "    }\n",
    "\n",
    "    # Corrected way to save the data as pickle files\n",
    "    with open(f'/Users/justint/Library/CloudStorage/OneDrive-Personal/Desktop/Academic Stuff/Arias Research/EAT/Paper_EAT_2025/Blender/EAT_noMag/run{run_iter}+1_6/atom_data.json', 'w') as pkl_file:  # Note 'wb' for binary write\n",
    "        json.dump(interp_list, pkl_file)\n",
    "\n",
    "    with open(f'/Users/justint/Library/CloudStorage/OneDrive-Personal/Desktop/Academic Stuff/Arias Research/EAT/Paper_EAT_2025/Blender/EAT_noMag/run{run_iter}+1_6/element_colors.json', 'w') as pkl_file:\n",
    "        json.dump(element_colors, pkl_file)\n",
    "\n",
    "    with open(f'/Users/justint/Library/CloudStorage/OneDrive-Personal/Desktop/Academic Stuff/Arias Research/EAT/Paper_EAT_2025/Blender/EAT_noMag/run{run_iter}+1_6/element_sizes.json', 'w') as pkl_file:\n",
    "        json.dump(element_sizes, pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved frames/frame_000.png\n",
      "Saved frames/frame_001.png\n",
      "Saved frames/frame_002.png\n",
      "Saved frames/frame_003.png\n",
      "Saved frames/frame_004.png\n",
      "Saved frames/frame_005.png\n",
      "Saved frames/frame_006.png\n",
      "Saved frames/frame_007.png\n",
      "Saved frames/frame_008.png\n",
      "Saved frames/frame_009.png\n",
      "Saved frames/frame_010.png\n",
      "Saved frames/frame_011.png\n",
      "Saved frames/frame_012.png\n",
      "Saved frames/frame_013.png\n",
      "Saved frames/frame_014.png\n",
      "Saved frames/frame_015.png\n",
      "Saved frames/frame_016.png\n",
      "Saved frames/frame_017.png\n",
      "Saved frames/frame_018.png\n",
      "Saved frames/frame_019.png\n",
      "Saved frames/frame_020.png\n",
      "Saved frames/frame_021.png\n",
      "Saved frames/frame_022.png\n",
      "Saved frames/frame_023.png\n",
      "Saved frames/frame_024.png\n",
      "Saved frames/frame_025.png\n",
      "Saved frames/frame_026.png\n",
      "Saved frames/frame_027.png\n",
      "Saved frames/frame_028.png\n",
      "Saved frames/frame_029.png\n",
      "Saved frames/frame_030.png\n",
      "Saved frames/frame_031.png\n",
      "Saved frames/frame_032.png\n",
      "Saved frames/frame_033.png\n",
      "Saved frames/frame_034.png\n",
      "Saved frames/frame_035.png\n",
      "Saved frames/frame_036.png\n",
      "Saved frames/frame_037.png\n",
      "Saved frames/frame_038.png\n",
      "Saved frames/frame_039.png\n",
      "Saved frames/frame_040.png\n",
      "Saved frames/frame_041.png\n",
      "Saved frames/frame_042.png\n",
      "Saved frames/frame_043.png\n",
      "Saved frames/frame_044.png\n",
      "Saved frames/frame_045.png\n",
      "Saved frames/frame_046.png\n",
      "Saved frames/frame_047.png\n",
      "Saved frames/frame_048.png\n",
      "Saved frames/frame_049.png\n",
      "Saved frames/frame_050.png\n",
      "Saved frames/frame_051.png\n",
      "Saved frames/frame_052.png\n",
      "Saved frames/frame_053.png\n",
      "Saved frames/frame_054.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Ensure the directory for saving images exists\n",
    "output_dir = \"frames\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Your data array\n",
    "values = []\n",
    "for entry in interp_list:\n",
    "    values.append(entry['binding'])\n",
    "values = np.array(values)\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=300)  # Higher DPI for better quality\n",
    "ax.axis('off')\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Initialize the text object\n",
    "text = ax.text(0.5, 0.5, '', fontsize=24, color='black',\n",
    "               ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "# Loop over each value and save each frame as a .png file\n",
    "for i, value in enumerate(values):\n",
    "    # Set the text for the current frame with escaped braces for LaTeX-style formatting\n",
    "    text.set_text(r'$\\Delta G_{{O^*}} - \\Delta G_{{HO^*}} = {:.2f} \\, \\mathrm{{eV}}$'.format(value))\n",
    "    \n",
    "    # Save the current frame as a .png file\n",
    "    filename = os.path.join(output_dir, f\"frame_{i:03d}.png\")\n",
    "    plt.savefig(filename, bbox_inches='tight', facecolor='white', dpi=300)\n",
    "    print(f\"Saved {filename}\")\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1919, 1446) to (1920, 1456) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added dG_frames/frame_000.png to the video.\n",
      "Added dG_frames/frame_001.png to the video.\n",
      "Added dG_frames/frame_002.png to the video.\n",
      "Added dG_frames/frame_003.png to the video.\n",
      "Added dG_frames/frame_004.png to the video.\n",
      "Added dG_frames/frame_005.png to the video.\n",
      "Added dG_frames/frame_006.png to the video.\n",
      "Added dG_frames/frame_007.png to the video.\n",
      "Added dG_frames/frame_008.png to the video.\n",
      "Added dG_frames/frame_009.png to the video.\n",
      "Added dG_frames/frame_010.png to the video.\n",
      "Added dG_frames/frame_011.png to the video.\n",
      "Added dG_frames/frame_012.png to the video.\n",
      "Added dG_frames/frame_013.png to the video.\n",
      "Added dG_frames/frame_014.png to the video.\n",
      "Added dG_frames/frame_015.png to the video.\n",
      "Added dG_frames/frame_016.png to the video.\n",
      "Added dG_frames/frame_017.png to the video.\n",
      "Added dG_frames/frame_018.png to the video.\n",
      "Added dG_frames/frame_019.png to the video.\n",
      "Added dG_frames/frame_020.png to the video.\n",
      "Added dG_frames/frame_021.png to the video.\n",
      "Added dG_frames/frame_022.png to the video.\n",
      "Added dG_frames/frame_023.png to the video.\n",
      "Added dG_frames/frame_024.png to the video.\n",
      "Added dG_frames/frame_025.png to the video.\n",
      "Added dG_frames/frame_026.png to the video.\n",
      "Added dG_frames/frame_027.png to the video.\n",
      "Added dG_frames/frame_028.png to the video.\n",
      "Added dG_frames/frame_029.png to the video.\n",
      "Added dG_frames/frame_030.png to the video.\n",
      "Added dG_frames/frame_031.png to the video.\n",
      "Added dG_frames/frame_032.png to the video.\n",
      "Added dG_frames/frame_033.png to the video.\n",
      "Added dG_frames/frame_034.png to the video.\n",
      "Added dG_frames/frame_035.png to the video.\n",
      "Added dG_frames/frame_036.png to the video.\n",
      "Added dG_frames/frame_037.png to the video.\n",
      "Added dG_frames/frame_038.png to the video.\n",
      "Added dG_frames/frame_039.png to the video.\n",
      "Added dG_frames/frame_040.png to the video.\n",
      "Added dG_frames/frame_041.png to the video.\n",
      "Added dG_frames/frame_042.png to the video.\n",
      "Added dG_frames/frame_043.png to the video.\n",
      "Added dG_frames/frame_044.png to the video.\n",
      "Added dG_frames/frame_045.png to the video.\n",
      "Added dG_frames/frame_046.png to the video.\n",
      "Added dG_frames/frame_047.png to the video.\n",
      "Added dG_frames/frame_048.png to the video.\n",
      "Added dG_frames/frame_049.png to the video.\n",
      "Added dG_frames/frame_050.png to the video.\n",
      "Added dG_frames/frame_051.png to the video.\n",
      "Added dG_frames/frame_052.png to the video.\n",
      "Added dG_frames/frame_053.png to the video.\n",
      "Added dG_frames/frame_054.png to the video.\n",
      "Video saved as numerical_values_animation.mp4\n"
     ]
    }
   ],
   "source": [
    "import imageio.v2 as imageio\n",
    "import os\n",
    "\n",
    "# Directory where the frames are saved\n",
    "output_dir = \"dG_frames\"\n",
    "# Path to save the video file\n",
    "video_filename = 'numerical_values_animation.mp4'\n",
    "\n",
    "# Collect the frames in order\n",
    "frame_filenames = sorted([os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith('.png')])\n",
    "\n",
    "# Set the frames per second for the video\n",
    "fps = int(6)  # Adjust as needed\n",
    "\n",
    "# Create the video\n",
    "with imageio.get_writer(video_filename, fps=fps) as writer:\n",
    "    for filename in frame_filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        print(f\"Added {filename} to the video.\")\n",
    "\n",
    "print(f\"Video saved as {video_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
